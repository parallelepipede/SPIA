{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8a9c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annoy in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (1.17.0)\n",
      "Requirement already satisfied: apache_beam in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (2.37.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (1.7)\n",
      "Requirement already satisfied: pytz>=2018.3 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (2021.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (3.10.0.2)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (1.4.2)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (1.4.10)\n",
      "Requirement already satisfied: orjson<4.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (3.6.7)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (4.1.3)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (0.19.1)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (6.0.1)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (1.20.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (2.7.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (3.19.4)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (2.8.2)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (3.12.3)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (1.44.0)\n",
      "Requirement already satisfied: numpy<1.22.0,>=1.14.3 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from apache_beam) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from grpcio<2,>=1.29.0->apache_beam) (1.16.0)\n",
      "Requirement already satisfied: docopt in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from httplib2<0.20.0,>=0.8->apache_beam) (2.4.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from oauth2client<5,>=2.0.1->apache_beam) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from oauth2client<5,>=2.0.1->apache_beam) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from oauth2client<5,>=2.0.1->apache_beam) (4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.2)\n",
      "Requirement already satisfied: tensorflow_hub in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_hub) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/paul/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_hub) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install annoy\n",
    "!pip install apache_beam\n",
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e02137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "import tensorflow_hub as hub\n",
    "import annoy\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bf0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_fn = None\n",
    "#model_url = 'https://hub.tensorflow.google.cn/google/universal-sentence-encoder/4'\n",
    "model_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n",
    "\n",
    "def generate_embeddings(text, model_url, random_projection_matrix=None):\n",
    "    # Beam will run this function in different processes that need to\n",
    "    global embed_fn\n",
    "    if embed_fn is None:\n",
    "        embed_fn = hub.load(model_url)\n",
    "        embedding = embed_fn(text).numpy()\n",
    "    if random_projection_matrix is not None:\n",
    "        embedding = random_projection_matrix.fit_transform(embedding)\n",
    "        #embedding = embedding.dot(random_projection_matrix)\n",
    "    return text, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39109336",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = 'lowercase_words.txt'\n",
    "reduced_voc = 'lowercase_reduced_words.txt'\n",
    "extension = ['es','s','d','ed','ment', 'ement','ive','ing','ion','ions','ted',\n",
    "             'red','ded','ence','rence', 'ly', 'y']\n",
    "def preprocess_vocabulary() : \n",
    "    def is_extension(root, word):\n",
    "        for ext in extension : \n",
    "            if root + ext == word : \n",
    "                return True\n",
    "            if root[:-1] + ext == word : \n",
    "                return True\n",
    "        return False\n",
    "        #return word.startswith(root[:-1])\n",
    "\n",
    "    with open(vocabulary, 'r') as voc : \n",
    "        lines = voc.readlines()\n",
    "        lines = list(map(str.strip,lines))\n",
    "\n",
    "    with open(reduced_voc, 'w') as voc : \n",
    "        index = 0\n",
    "        while index < len(lines) :\n",
    "            j = index + 1\n",
    "            while j < len(lines) and is_extension(lines[index], lines[j]): \n",
    "                j += 1\n",
    "            voc.write(lines[index]+'\\n')\n",
    "            index = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97f8e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65bf0827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40005\n"
     ]
    }
   ],
   "source": [
    "#preprocess_vocabulary()\n",
    "with open(reduced_voc, 'r') as voc : \n",
    "    lines = voc.readlines()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba386d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Deleting lock file /var/folders/nm/lm6vpz5s5v7_bt4xx0jq3fq00000gn/T/tfhub_modules/063d866c06683311b44b4992fd46003be952409c.lock due to inactivity.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nm/lm6vpz5s5v7_bt4xx0jq3fq00000gn/T/ipykernel_3497/17516873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elephant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/nm/lm6vpz5s5v7_bt4xx0jq3fq00000gn/T/ipykernel_3497/726482942.py\u001b[0m in \u001b[0;36mgenerate_embeddings\u001b[0;34m(text, model_url, random_projection_matrix)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0membed_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membed_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0membed_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrandom_projection_matrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected a string, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   is_hub_module_v1 = tf.io.gfile.exists(\n\u001b[1;32m     94\u001b[0m       native_module.get_module_proto_path(module_path))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/compressed_module_resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m     65\u001b[0m           response, tmp_dir)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     return resolver.atomic_download(handle, download, module_dir,\n\u001b[0m\u001b[1;32m     68\u001b[0m                                     self._lock_file_timeout_sec())\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36matomic_download\u001b[0;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading TF-Hub Module '%s'.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mdownload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;31m# Write module descriptor to capture information about which module was\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# downloaded by whom and when. The file stored at the same level as a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/compressed_module_resolver.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(handle, tmp_dir)\u001b[0m\n\u001b[1;32m     62\u001b[0m           self._append_compressed_format_query(handle))\n\u001b[1;32m     63\u001b[0m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       return resolver.DownloadManager(handle).download_and_uncompress(\n\u001b[0m\u001b[1;32m     65\u001b[0m           response, tmp_dir)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36mdownload_and_uncompress\u001b[0;34m(self, fileobj, dst_path)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       file_utils.extract_tarfile_to_destination(\n\u001b[0m\u001b[1;32m    190\u001b[0m           fileobj, dst_path, log_function=self._log_progress)\n\u001b[1;32m    191\u001b[0m       total_size_str = tf_utils.bytes_to_readable_str(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/file_utils.py\u001b[0m in \u001b[0;36mextract_tarfile_to_destination\u001b[0;34m(fileobj, dst_path, log_function)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mextract_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_target_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_target_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow_hub/file_utils.py\u001b[0m in \u001b[0;36mextract_file\u001b[0;34m(tgz, tarinfo, dst_path, buffer_size, log_function)\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;34m\"\"\"Return the next size number of bytes from the stream.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                 \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_embeddings(['elephant'], model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_example(entries):\n",
    "    examples = []\n",
    "    text, embeddings = entries\n",
    "    for i in range(len(text)): \n",
    "        texti = text[i]\n",
    "        embeddingsi  = embeddings[i]\n",
    "        features = {\n",
    "            'text' : tf.train.Feature(\n",
    "                bytes_list = tf.train.BytesList(value = [texti.encode('utf-8')])), \n",
    "            'embedding' : tf.train.Feature(\n",
    "                float_list = tf.train.BytesList(value = embeddingsi.tolist()))\n",
    "        }\n",
    "        example = tf.train.Example(\n",
    "            features = tf.train.Features(feature = features)).SerializeToString(deterministic = True)\n",
    "        \n",
    "        examples.append(example)\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88aa2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_projection_matrix(projected_dim):\n",
    "    random_projection_matrix = GaussianRandomProjection(n_components=projected_dim).T\n",
    "    print(random_projection_matrix.n_components_, random_projection_matrix.n_features_in_)\n",
    "    print(\"A Gaussian random weight matrix was creates with shape of {}\".format(random_projection_matrix.shape))\n",
    "    print('Storing random projection matrix to disk...')\n",
    "    with open('random_projection_matrix', 'wb') as handle:\n",
    "        pickle.dump(random_projection_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return random_projection_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca93e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hub2emb(args):\n",
    "\n",
    "    options = beam.options.pipeline_options.PipelineOptions(**args)\n",
    "    args = namedtuple(\"options\", args.keys())(*args.values())\n",
    "\n",
    "    with beam.Pipeline(args.runner, options=options) as pipeline:\n",
    "    (\n",
    "        pipeline\n",
    "        | 'Read sentences from files' >> beam.io.ReadFromText(\n",
    "            file_pattern=args.data_dir)\n",
    "        | 'Batch elements' >> util.BatchElements(\n",
    "            min_batch_size=args.batch_size, max_batch_size=args.batch_size)\n",
    "        | 'Generate embeddings' >> beam.Map(\n",
    "            generate_embeddings, args.model_url, args.random_projection_matrix)\n",
    "        | 'Encode to tf example' >> beam.FlatMap(to_tf_example)\n",
    "        | 'Write to TFRecords files' >> beam.io.WriteToTFRecord(\n",
    "            file_path_prefix='{}/emb'.format(args.output_dir),\n",
    "            file_name_suffix='.tfrecords')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadcc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_dim = 64 # Test with None value\n",
    "original_dim = hub.load(model_url)(['']).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee10f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "output_dir = tempfile.mkdtemp()\n",
    "original_dim = hub.load(model_url)(['']).shape[1]\n",
    "random_projection_matrix = None\n",
    "\n",
    "if projected_dim:\n",
    "    random_projection_matrix = generate_random_projection_weights(original_dim, projected_dim)\n",
    "\n",
    "args = {\n",
    "    'job_name': 'hub2emb-{}'.format(datetime.utcnow().strftime('%y%m%d-%H%M%S')),\n",
    "    'runner': 'DirectRunner',\n",
    "    'batch_size': 1024,\n",
    "    'data_dir': reduced_voc,\n",
    "    'output_dir': output_dir,\n",
    "    'model_url': model_url,\n",
    "    'random_projection_matrix': random_projection_matrix,\n",
    "}\n",
    "\n",
    "print(\"Pipeline args are set.\")\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_file = os.path.join(output_dir, 'emb-00000-of-00001.tfrecords')\n",
    "sample = 5\n",
    "\n",
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'text': tf.io.FixedLenFeature([], tf.string),\n",
    "    'embedding': tf.io.FixedLenFeature([projected_dim], tf.float32)\n",
    "}\n",
    "\n",
    "def _parse_example(example):\n",
    "  # Parse the input `tf.Example` proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example, feature_description)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(embed_file)\n",
    "for record in dataset.take(sample).map(_parse_example):\n",
    "    print(\"{}: {}\".format(record['text'].numpy().decode('utf-8'), record['embedding'].numpy()[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "453e8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(embedding_files_pattern, index_filename, vector_length, metric='angular', num_trees=100):\n",
    "    annoy_index = annoy.AnnoyIndex(vector_length, metric=metric)\n",
    "    \n",
    "    mapping = {}\n",
    "    with open()\n",
    "    print('Found {} embedding file(s).'.format(num_files))\n",
    "\n",
    "    item_counter = 0\n",
    "    for i, embed_file in enumerate(embed_files):\n",
    "        print('Loading embeddings in file {} of {}...'.format(i+1, num_files))\n",
    "        dataset = tf.data.TFRecordDataset(embed_file)\n",
    "        for record in dataset.map(_parse_example):\n",
    "            text = record['text'].numpy().decode(\"utf-8\")\n",
    "            embedding = record['embedding'].numpy()\n",
    "            mapping[item_counter] = text\n",
    "            annoy_index.add_item(item_counter, embedding)\n",
    "            item_counter += 1\n",
    "            if item_counter % 100000 == 0:\n",
    "                print('{} items loaded to the index'.format(item_counter))\n",
    "\n",
    "    print('A total of {} items added to the index'.format(item_counter))\n",
    "\n",
    "    print('Building the index with {} trees...'.format(num_trees))\n",
    "    annoy_index.build(n_trees=num_trees)\n",
    "    print('Index is successfully built.')\n",
    "\n",
    "    print('Saving index to disk...')\n",
    "    annoy_index.save(index_filename)\n",
    "    print('Index is saved to disk.')\n",
    "    print(\"Index file size: {} GB\".format(\n",
    "        round(os.path.getsize(index_filename) / float(1024 ** 3), 2)))\n",
    "    annoy_index.unload()\n",
    "\n",
    "    print('Saving mapping to disk...')\n",
    "    with open(index_filename + '.mapping', 'wb') as handle:\n",
    "        pickle.dump(mapping, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('Mapping is saved to disk.')\n",
    "    print(\"Mapping file size: {} MB\".format(\n",
    "        round(os.path.getsize(index_filename + '.mapping') / float(1024 ** 2), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c49f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d4520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a155e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
